# -*- coding: utf-8 -*-
"""Copy of bonus_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WYUXWl-LoySLjqSlQ81TRCtEYlbMf_9e

# Importing libraries
"""

from scipy import linalg
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA
from sklearn.model_selection import cross_val_score

"""# Mounting Drive"""

# from google.colab import drive
# drive.mount("/content/gdrive")

"""# Importing dataset"""

data=pd.read_csv(r"D:\IIT Jodhpur\Study Material\PRML\Minor project\Mruganshi\flight_data.csv")
data

"""### Splitting in training and testing datatset"""

train,test=train_test_split(data,train_size=0.7,random_state=1)
train

"""### Handling null values"""

print("Original Length of Training Set : ", len(train))

train = train.dropna()

test = test.dropna()
print("Length of Training Set after dropping NaN: ", len(train))

"""# EDA

### Cleaning Journey Date
"""

#Training Set

train['Journey_Day'] = pd.to_datetime(train.Date_of_Journey, format='%d/%m/%Y').dt.day
train['Journey_Month'] = pd.to_datetime(train.Date_of_Journey, format='%d/%m/%Y').dt.month

# Test Set

test['Journey_Day'] = pd.to_datetime(test.Date_of_Journey, format='%d/%m/%Y').dt.day
test['Journey_Month'] = pd.to_datetime(test.Date_of_Journey, format='%d/%m/%Y').dt.month

# Compare the dates and delete the original date feature

train.drop(labels = 'Date_of_Journey', axis = 1, inplace = True)
test.drop(labels = 'Date_of_Journey', axis = 1, inplace = True)

"""### Cleaning Duration"""

# Training Set

duration = list(train['Duration'])

for i in range(len(duration)) :
    if len(duration[i].split()) != 2:
        if 'h' in duration[i] :
            duration[i] = duration[i].strip() + ' 0m'
        elif 'm' in duration[i] :
            duration[i] = '0h {}'.format(duration[i].strip())

dur_hours = []
dur_minutes = []  

for i in range(len(duration)) :
    dur_hours.append(int(duration[i].split()[0][:-1]))
    dur_minutes.append(int(duration[i].split()[1][:-1]))
    
train['Duration_hours'] = dur_hours
train['Duration_minutes'] =dur_minutes

train.drop(labels = 'Duration', axis = 1, inplace = True)


# Test Set

durationT = list(test['Duration'])

for i in range(len(durationT)) :
    if len(durationT[i].split()) != 2:
        if 'h' in durationT[i] :
            durationT[i] = durationT[i].strip() + ' 0m'
        elif 'm' in durationT[i] :
            durationT[i] = '0h {}'.format(durationT[i].strip())
            
dur_hours = []
dur_minutes = []  

for i in range(len(durationT)) :
    dur_hours.append(int(durationT[i].split()[0][:-1]))
    dur_minutes.append(int(durationT[i].split()[1][:-1]))
  
    
test['Duration_hours'] = dur_hours
test['Duration_minutes'] = dur_minutes

test.drop(labels = 'Duration', axis = 1, inplace = True)

"""### Cleaning Departure and Arrival Times"""

# Training Set


train['Depart_Time_Hour'] = pd.to_datetime(train.Dep_Time).dt.hour
train['Depart_Time_Minutes'] = pd.to_datetime(train.Dep_Time).dt.minute

train.drop(labels = 'Dep_Time', axis = 1, inplace = True)


train['Arr_Time_Hour'] = pd.to_datetime(train.Arrival_Time).dt.hour
train['Arr_Time_Minutes'] = pd.to_datetime(train.Arrival_Time).dt.minute

train.drop(labels = 'Arrival_Time', axis = 1, inplace = True)


# Test Set


test['Depart_Time_Hour'] = pd.to_datetime(test.Dep_Time).dt.hour
test['Depart_Time_Minutes'] = pd.to_datetime(test.Dep_Time).dt.minute


test.drop(labels = 'Dep_Time', axis = 1, inplace = True)

test['Arr_Time_Hour'] = pd.to_datetime(test.Arrival_Time).dt.hour
test['Arr_Time_Minutes'] = pd.to_datetime(test.Arrival_Time).dt.minute

test.drop(labels = 'Arrival_Time', axis = 1, inplace = True)

"""# Preprocessing the Dataset"""

y_train = train.iloc[:,6].values  
x_train = train.iloc[:,train.columns != 'Price'].values
x_test = test.iloc[:,test.columns != 'Price'].values
y_test = test.iloc[:,6].values

"""### Handling categorical data"""

from sklearn.preprocessing import LabelEncoder

le1 = LabelEncoder()
le2 = LabelEncoder()

# Training Set    

x_train[:,0] = le1.fit_transform(x_train[:,0])
x_train[:,1] = le1.fit_transform(x_train[:,1])
x_train[:,2] = le1.fit_transform(x_train[:,2])
x_train[:,3] = le1.fit_transform(x_train[:,3])
x_train[:,4] = le1.fit_transform(x_train[:,4])
x_train[:,5] = le1.fit_transform(x_train[:,5])

# Test Set


x_test[:,0] = le2.fit_transform(x_test[:,0])
x_test[:,1] = le2.fit_transform(x_test[:,1])
x_test[:,2] = le2.fit_transform(x_test[:,2])
x_test[:,3] = le2.fit_transform(x_test[:,3])
x_test[:,4] = le2.fit_transform(x_test[:,4])
x_test[:,5] = le2.fit_transform(x_test[:,5])

"""# Feature Scaling

### Training

### Testing
"""

x_test=pd.DataFrame(x_test)
x_train=pd.DataFrame(x_train)

"""# Feature Selection

### Finds correlation between Independent and dependent attributes

### Important feature using ExtraTreesRegressor

### plot graph of feature importances for better visualization

# Fitting model

### using Random Forest
"""

from sklearn.ensemble import RandomForestRegressor
reg_rf = RandomForestRegressor()
reg_rf.fit(x_train, y_train)
y_pred=reg_rf.predict(x_test)

reg_rf.score(x_train, y_train)

reg_rf.score(x_test, y_test)

